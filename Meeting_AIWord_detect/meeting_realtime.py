#!/usr/bin/env python3
import speech_recognition as sr
import os
import time
import argparse
import threading
from collections import deque
from datetime import datetime
import json
import re

# (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) Thai NLP
try:
    from pythainlp import word_tokenize
    from pythainlp.tokenize import sent_tokenize
    HAS_THAI = True
except Exception:
    HAS_THAI = False

# (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) Gemini LLM
try:
    import google.generativeai as genai
    HAS_GEMINI = True
except Exception:
    HAS_GEMINI = False


class ThaiMeetingSummarizer:
    """
    ‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏à‡∏≤‡∏Å transcript ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ (offline)
    - ‡∏î‡∏∂‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å (topics) ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢
    - ‡∏î‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (decisions) ‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ trigger
    - ‡∏î‡∏∂‡∏á Action items (assignee, task, due) ‡πÅ‡∏ö‡∏ö heuristic
    - ‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á/‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° (risks_or_followups)
    """
    def __init__(self, language="th-TH"):
        self.language = language
        self.utterances = []  # list of (timestamp, text)

        self.topic_stopwords = set([
            "‡∏Ñ‡∏£‡∏±‡∏ö","‡∏Ñ‡πà‡∏∞","‡∏Ñ‡∏∞","‡πÄ‡∏£‡∏≤","‡πÄ‡∏Ç‡∏≤","‡∏ó‡∏µ‡πà","‡∏ß‡πà‡∏≤","‡πÅ‡∏•‡∏∞","‡∏´‡∏£‡∏∑‡∏≠","‡∏Å‡πá","‡∏Ñ‡∏∑‡∏≠","‡∏°‡∏±‡∏ô","‡πÑ‡∏î‡πâ","‡πÜ","‡∏ô‡∏∞","‡∏Ñ‡πà‡∏∞","‡∏Ñ‡∏£‡∏±‡∏ö",
            "‡πÄ‡∏≠‡πà‡∏≠","‡∏≠‡πà‡∏≤","‡πÅ‡∏ö‡∏ö‡∏ß‡πà‡∏≤","‡∏Ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤","‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠","‡πÅ‡∏ö‡∏ö"
        ])

        # ‡∏Ñ‡∏≥‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì (‡πÑ‡∏ó‡∏¢)
        self.decision_triggers = ["‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à", "‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥", "‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô", "‡∏™‡∏£‡∏∏‡∏õ‡∏ß‡πà‡∏≤", "‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ", "‡∏ï‡∏Å‡∏•‡∏á‡∏ß‡πà‡∏≤"]
        self.action_triggers   = ["‡∏°‡∏≠‡∏ö‡∏´‡∏°‡∏≤‡∏¢", "‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö", "‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥", "‡∏à‡∏∞‡∏ó‡∏≥", "‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£", "‡∏†‡∏≤‡∏¢‡πÉ‡∏ô", "‡∏Å‡πà‡∏≠‡∏ô", "‡∏™‡πà‡∏á", "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°", "‡πÄ‡∏î‡∏î‡πÑ‡∏•‡∏ô‡πå", "‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡πà‡∏á"]
        self.risk_triggers     = ["‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", "‡∏õ‡∏±‡∏ç‡∏´‡∏≤", "‡∏ï‡∏¥‡∏î‡∏Ç‡∏±‡∏î", "‡∏Ñ‡πâ‡∏≤‡∏á", "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏£‡πá‡∏à", "‡∏£‡∏≠", "‡∏≠‡∏≤‡∏à", "‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö", "‡∏ö‡∏•‡πá‡∏≠‡∏Ñ"]

        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏´‡∏≤ assignee/‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
        self.assignee_patterns = [
            r"(‡∏Ñ‡∏∏‡∏ì[^\s]+)", r"(‡∏û‡∏µ‡πà[^\s]+)", r"(‡∏ô‡∏≤‡∏¢[^\s]+)", r"(‡∏ô‡∏≤‡∏á[^\s]+)", r"(‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß[^\s]+)"
        ]
        # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà/‡πÄ‡∏î‡∏î‡πÑ‡∏•‡∏ô‡πå‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡πÑ‡∏ó‡∏¢/‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)
        self.due_patterns = [
            r"(‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\s*\d+\s*(‡∏ß‡∏±‡∏ô|‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå|‡πÄ‡∏î‡∏∑‡∏≠‡∏ô))",
            r"(‡∏Å‡πà‡∏≠‡∏ô\s*‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà\s*\d{1,2}/\d{1,2}/\d{2,4})",
            r"(‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\s*‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏ô‡∏µ‡πâ|‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\s*‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ|‡∏™‡∏¥‡πâ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ|‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤|‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤)"
        ]

    def add_utterance(self, ts, text):
        self.utterances.append((ts, text))

    def _thai_sentences(self, text):
        if HAS_THAI:
            try:
                return [s.strip() for s in sent_tokenize(text) if s.strip()]
            except Exception:
                pass
        # fallback
        parts = re.split(r"[\.!\?\n]|[ ]{2,}|[|]", text)
        return [p.strip() for p in parts if p.strip()]

    def _thai_words(self, text):
        if HAS_THAI:
            try:
                return [w for w in word_tokenize(text) if w.strip()]
            except Exception:
                pass
        # fallback: ‡πÅ‡∏¢‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á
        return [w for w in re.split(r"\s+", text) if w.strip()]

    def _extract_topics(self, all_text, topn=5):
        words = self._thai_words(all_text)
        freq = {}
        for w in words:
            if w in self.topic_stopwords:
                continue
            if len(w) < 2:
                continue
            freq[w] = freq.get(w, 0) + 1
        topics = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:topn]
        return [t[0] for t in topics]

    def _match_any(self, text, triggers):
        return any(t in text for t in triggers)

    def _extract_assignee(self, sentence):
        for pat in self.assignee_patterns:
            m = re.search(pat, sentence)
            if m:
                return m.group(1)
        return "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"

    def _extract_due(self, sentence):
        for pat in self.due_patterns:
            m = re.search(pat, sentence)
            if m:
                return m.group(1)
        return "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"

    def summarize_offline(self):
        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        all_text = "\n".join([t for _, t in self.utterances]).strip()
        topics = self._extract_topics(all_text, topn=6)

        decisions = []
        action_items = []
        risks = []
        highlights = []

        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏µ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
        for ts, text in self.utterances:
            for sent in self._thai_sentences(text):
                if self._match_any(sent, self.decision_triggers):
                    decisions.append(sent)
                if self._match_any(sent, self.action_triggers):
                    action_items.append({
                        "assignee": self._extract_assignee(sent),
                        "task": sent,
                        "due": self._extract_due(sent)
                    })
                if self._match_any(sent, self.risk_triggers):
                    risks.append(sent)

        # ‡πÑ‡∏Æ‡πÑ‡∏•‡∏ï‡πå: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏¢‡∏≤‡∏ß/‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        for ts, text in self.utterances:
            if len(text) >= 25 and (self._match_any(text, self.decision_triggers + self.action_triggers) or len(text) > 60):
                highlights.append(text)
        highlights = highlights[:8]

        summary = {
            "summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÅ‡∏ö‡∏ö‡∏≠‡∏≠‡∏ü‡πÑ‡∏•‡∏ô‡πå (heuristic) ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤",
            "topics": topics,
            "decisions": decisions[:10],
            "action_items": action_items[:20],
            "risks_or_followups": risks[:10],
            "highlights": highlights
        }
        return summary

    def summarize_with_gemini(self):
        api_key = os.environ.get("GOOGLE_API_KEY")
        if not (HAS_GEMINI and api_key):
            return None
        genai.configure(api_key==api_key)
        model = genai.GenerativeModel(
            "gemini-1.5-flash",
            generation_config={
                "temperature": 0.2,
                "top_p": 0.9,
                "max_output_tokens": 2048,
                "response_mime_type": "application/json",
            },
        )
        all_text = "\n".join([t for _, t in self.utterances]).strip()
        prompt = (
            "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏≤‡∏ô‡∏∏‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ "
            "‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô JSON ‡∏Å‡∏±‡∏ö‡∏Ñ‡∏µ‡∏¢‡πå: summary, topics, decisions, "
            "action_items (assignee, task, due), risks_or_followups, highlights. "
            "‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'.\n\n"
            f"{all_text}"
        )
        try:
            resp = model.generate_content(prompt)
            data = json.loads(resp.text)
            return data
        except Exception:
            return None

    def summarize(self, prefer_gemini=True):
        if prefer_gemini:
            data = self.summarize_with_gemini()
            if data:
                return data
        return self.summarize_offline()


class RealTimeAugmenter:
    """
    ‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå -> ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Google -> ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î -> ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°
    (‡∏ï‡∏±‡∏î‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô: ‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢, WPM, Keyword ‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß)
    """
    def __init__(self,
                 language="th-TH",
                 mic_index=None,
                 summarize_interval=30):
        # ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
        self.language = language
        self.mic_index = mic_index
        self.SUMMARIZE_INTERVAL = summarize_interval

        # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        self.live_transcript = deque(maxlen=5)
        self.lock = threading.Lock()
        self.all_utterances = []  # list of (ts, text)
        self.last_text = None

        # STT
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone(device_index=self.mic_index)
        self.recognizer.pause_threshold = 0.6
        self.recognizer.non_speaking_duration = 0.4
        self.google_key = os.environ.get("GOOGLE_SPEECH_RECOGNITION_API_KEY")

        # Summarizer
        self.summarizer = ThaiMeetingSummarizer(language=self.language)
        self.last_summary_time = 0
        self.live_summary_cache = None

        # Output
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.out_dir = "output_meeting"
        os.makedirs(self.out_dir, exist_ok=True)
        self.base_name = f"meeting_{ts}"
        self.out_transcript = os.path.join(self.out_dir, f"{self.base_name}.transcript.txt")
        self.out_summary_json = os.path.join(self.out_dir, f"{self.base_name}.summary.json")
        self.out_summary_txt = os.path.join(self.out_dir, f"{self.base_name}.summary.txt")

    # ---------- UI ----------
    def _clear_screen(self):
        os.system('cls' if os.name == 'nt' else 'clear')

    def _display_dashboard(self):
        self._clear_screen()
        print("="*70)
        print("--- üöÄ Real-time Meeting Summarizer (Google STT) üöÄ ---")
        print("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏±‡∏ö‡∏ü‡∏±‡∏á... (‡∏Å‡∏î Ctrl+C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î)")
        print("="*70)

        # Live transcript
        print("\nüìú Live Transcript:")
        with self.lock:
            if not self.live_transcript:
                print("   ...")
            else:
                for t in self.live_transcript:
                    print(f"   - {t}")

        # Live summary (cache)
        print("\nüß≠ Live Meeting Summary (‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î):")
        if self.live_summary_cache:
            s = self.live_summary_cache
            topics = ", ".join(s.get("topics", [])[:5]) or "-"
            decisions_n = len(s.get("decisions", []))
            actions_n = len(s.get("action_items", []))
            risks_n = len(s.get("risks_or_followups", []))
            print(f"   ‚Ä¢ ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å: {topics}")
            print(f"   ‚Ä¢ ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à: {decisions_n} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            print(f"   ‚Ä¢ Action items: {actions_n} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            print(f"   ‚Ä¢ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á/‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°: {risks_n} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        else:
            print("   ...")

        print("\n" + "-"*70)

    # ---------- Processing ----------
    def _process_text(self, text):
        text = text.strip()
        if not text:
            return
        # ‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥‡∏ï‡∏¥‡∏î‡πÜ ‡∏Å‡∏±‡∏ô
        if self.last_text and text == self.last_text:
            return
        self.last_text = text

        now = time.time()
        with self.lock:
            self.live_transcript.append(text)
            self.all_utterances.append((now, text))
            self.summarizer.add_utterance(now, text)

    # ---------- Callback ----------
    def _audio_callback(self, recognizer, audio):
        try:
            result = recognizer.recognize_google(audio, language=self.language, key=self.google_key)
            self._process_text(result)
        except sr.UnknownValueError:
            pass
        except sr.RequestError as e:
            with self.lock:
                # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô transcript ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
                self.live_transcript.append(f"[‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠: {e}]")

    # ---------- Save ----------
    def _save_results(self, final_summary):
        # Transcript
        with open(self.out_transcript, "w", encoding="utf-8") as f:
            with self.lock:
                for ts, text in self.all_utterances:
                    rel = ts - (self.all_utterances[0][0] if self.all_utterances else ts)
                    f.write(f"[+{rel:0.1f}s] {text}\n")
        # Summary JSON
        with open(self.out_summary_json, "w", encoding="utf-8") as f:
            json.dump(final_summary, f, ensure_ascii=False, indent=2)
        # Summary TXT (‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢)
        lines = []
        lines.append("‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° (‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)")
        lines.append("")
        if final_summary.get("summary"):
            lines.append(f"- ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡πà‡∏≠: {final_summary['summary']}")
        if final_summary.get("topics"):
            lines.append("- ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å:")
            for t in final_summary["topics"]:
                lines.append(f"  ‚Ä¢ {t}")
        if final_summary.get("decisions"):
            lines.append("- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à:")
            for d in final_summary["decisions"]:
                lines.append(f"  ‚Ä¢ {d}")
        if final_summary.get("action_items"):
            lines.append("- Action items:")
            for a in final_summary["action_items"]:
                lines.append(f"  ‚Ä¢ ‡∏ú‡∏π‡πâ‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö: {a.get('assignee','‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}, ‡∏á‡∏≤‡∏ô: {a.get('task','')}, ‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏≤‡∏¢: {a.get('due','‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
        if final_summary.get("risks_or_followups"):
            lines.append("- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á/‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°:")
            for r in final_summary["risks_or_followups"]:
                lines.append(f"  ‚Ä¢ {r}")
        if final_summary.get("highlights"):
            lines.append("- ‡πÑ‡∏Æ‡πÑ‡∏•‡∏ï‡πå:")
            for h in final_summary["highlights"]:
                lines.append(f"  ‚Ä¢ {h}")
        with open(self.out_summary_txt, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))

        print(f"\n‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢:")
        print(f"- Transcript: {self.out_transcript}")
        print(f"- Summary JSON: {self.out_summary_json}")
        print(f"- Summary TXT: {self.out_summary_txt}")

    # ---------- Run ----------
    def run(self):
        print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô... ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Ambient Noise")
        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source, duration=2.0)
        print("‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß! ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢")

        stop_listening = self.recognizer.listen_in_background(self.microphone, self._audio_callback)

        try:
            while True:
                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞
                if time.time() - self.last_summary_time > self.SUMMARIZE_INTERVAL:
                    self.live_summary_cache = self.summarizer.summarize(prefer_gemini=True)
                    self.last_summary_time = time.time()

                self._display_dashboard()
                time.sleep(0.6)
        except KeyboardInterrupt:
            print("\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô...")
            stop_listening(wait_for_stop=False)

            # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
            final_summary = self.summarizer.summarize(prefer_gemini=True)
            self._save_results(final_summary)
            print("‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö!")


def list_microphones():
    for i, name in enumerate(sr.Microphone.list_microphone_names()):
        print(f"[{i}] {name}")


def main():
    parser = argparse.ArgumentParser(description="Real-time Meeting Capturer & Summarizer (Google STT)")
    parser.add_argument("--language", default="th-TH", help="‡∏£‡∏´‡∏±‡∏™‡∏†‡∏≤‡∏©‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô th-TH, en-US)")
    parser.add_argument("--mic", type=int, default=None, help="index ‡∏Ç‡∏≠‡∏á‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô (‡∏î‡∏π‡∏à‡∏≤‡∏Å --list-mics)")
    parser.add_argument("--list-mics", action="store_true", help="‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡∏Ñ‡πå‡πÅ‡∏•‡∏∞‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
    parser.add_argument("--summarize-interval", type=int, default=30, help="‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ) ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠")
    args = parser.parse_args()

    if args.list_mics:
        list_microphones()
        return

    augmenter = RealTimeAugmenter(
        language=args.language,
        mic_index=args.mic,
        summarize_interval=args.summarize_interval
    )
    augmenter.run()


if __name__ == "__main__":
    main()
